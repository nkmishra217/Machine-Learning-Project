{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Price Prediction-Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 : DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      "battery_power    2000 non-null int64\n",
      "blue             2000 non-null int64\n",
      "clock_speed      2000 non-null float64\n",
      "dual_sim         2000 non-null int64\n",
      "fc               2000 non-null int64\n",
      "four_g           2000 non-null int64\n",
      "int_memory       2000 non-null int64\n",
      "m_dep            2000 non-null float64\n",
      "mobile_wt        2000 non-null int64\n",
      "n_cores          2000 non-null int64\n",
      "pc               2000 non-null int64\n",
      "px_height        2000 non-null int64\n",
      "px_width         2000 non-null int64\n",
      "ram              2000 non-null int64\n",
      "sc_h             2000 non-null int64\n",
      "sc_w             2000 non-null int64\n",
      "talk_time        2000 non-null int64\n",
      "three_g          2000 non-null int64\n",
      "touch_screen     2000 non-null int64\n",
      "wifi             2000 non-null int64\n",
      "price_range      2000 non-null int64\n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2   2         20       756  2549     9     7         19   \n",
       "1        136        3   6        905      1988  2631    17     3          7   \n",
       "2        145        5   6       1263      1716  2603    11     2          9   \n",
       "3        131        6   9       1216      1786  2769    16     8         11   \n",
       "4        141        2  14       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  \n",
       "0        0             0     1  \n",
       "1        1             1     0  \n",
       "2        1             1     0  \n",
       "3        1             0     0  \n",
       "4        1             1     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=dataset.iloc[:,0:20]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset.iloc[:,20]\n",
    "y.unique()\n",
    "# We have four price ranges as target values and will do binary classification in our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.replace({0:0,1:1,2:1,3:1})\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SCALING : We need to normallize and scale the data, so we'll use Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naresh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Naresh\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902597</td>\n",
       "      <td>-0.990050</td>\n",
       "      <td>0.830779</td>\n",
       "      <td>-1.019184</td>\n",
       "      <td>-0.762495</td>\n",
       "      <td>-1.043966</td>\n",
       "      <td>-1.380644</td>\n",
       "      <td>0.340740</td>\n",
       "      <td>1.349249</td>\n",
       "      <td>-1.101971</td>\n",
       "      <td>-1.305750</td>\n",
       "      <td>-1.408949</td>\n",
       "      <td>-1.146784</td>\n",
       "      <td>0.391703</td>\n",
       "      <td>-0.784983</td>\n",
       "      <td>0.283103</td>\n",
       "      <td>1.462493</td>\n",
       "      <td>-1.786861</td>\n",
       "      <td>-1.006018</td>\n",
       "      <td>0.986097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.495139</td>\n",
       "      <td>1.010051</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>0.957886</td>\n",
       "      <td>1.155024</td>\n",
       "      <td>0.687548</td>\n",
       "      <td>-0.120059</td>\n",
       "      <td>-0.664768</td>\n",
       "      <td>-0.645989</td>\n",
       "      <td>0.585778</td>\n",
       "      <td>1.704465</td>\n",
       "      <td>0.467317</td>\n",
       "      <td>1.114266</td>\n",
       "      <td>-0.635317</td>\n",
       "      <td>-0.734267</td>\n",
       "      <td>0.559641</td>\n",
       "      <td>0.994018</td>\n",
       "      <td>-1.014099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.537686</td>\n",
       "      <td>1.010051</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>-0.532099</td>\n",
       "      <td>0.957886</td>\n",
       "      <td>0.493546</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.209639</td>\n",
       "      <td>-0.645989</td>\n",
       "      <td>1.392684</td>\n",
       "      <td>1.074968</td>\n",
       "      <td>0.441498</td>\n",
       "      <td>-0.310171</td>\n",
       "      <td>-0.864922</td>\n",
       "      <td>-0.368140</td>\n",
       "      <td>0.559641</td>\n",
       "      <td>0.994018</td>\n",
       "      <td>-1.014099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.419319</td>\n",
       "      <td>1.010051</td>\n",
       "      <td>1.198517</td>\n",
       "      <td>-1.019184</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>-1.043966</td>\n",
       "      <td>-1.215274</td>\n",
       "      <td>1.034357</td>\n",
       "      <td>-0.261339</td>\n",
       "      <td>0.646842</td>\n",
       "      <td>-0.151168</td>\n",
       "      <td>1.286750</td>\n",
       "      <td>1.236971</td>\n",
       "      <td>0.594569</td>\n",
       "      <td>0.876859</td>\n",
       "      <td>0.512708</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>0.559641</td>\n",
       "      <td>-1.006018</td>\n",
       "      <td>-1.014099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.325906</td>\n",
       "      <td>1.010051</td>\n",
       "      <td>-0.395011</td>\n",
       "      <td>-1.019184</td>\n",
       "      <td>2.002254</td>\n",
       "      <td>0.957886</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.340740</td>\n",
       "      <td>0.021220</td>\n",
       "      <td>-1.101971</td>\n",
       "      <td>0.673534</td>\n",
       "      <td>1.268718</td>\n",
       "      <td>-0.091452</td>\n",
       "      <td>-0.657666</td>\n",
       "      <td>-1.022389</td>\n",
       "      <td>-0.864922</td>\n",
       "      <td>0.730240</td>\n",
       "      <td>0.559641</td>\n",
       "      <td>0.994018</td>\n",
       "      <td>-1.014099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.902597 -0.990050  0.830779 -1.019184 -0.762495 -1.043966 -1.380644   \n",
       "1 -0.495139  1.010051 -1.253064  0.981177 -0.992890  0.957886  1.155024   \n",
       "2 -1.537686  1.010051 -1.253064  0.981177 -0.532099  0.957886  0.493546   \n",
       "3 -1.419319  1.010051  1.198517 -1.019184 -0.992890 -1.043966 -1.215274   \n",
       "4  1.325906  1.010051 -0.395011 -1.019184  2.002254  0.957886  0.658915   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.340740  1.349249 -1.101971 -1.305750 -1.408949 -1.146784  0.391703   \n",
       "1  0.687548 -0.120059 -0.664768 -0.645989  0.585778  1.704465  0.467317   \n",
       "2  1.381165  0.134244  0.209639 -0.645989  1.392684  1.074968  0.441498   \n",
       "3  1.034357 -0.261339  0.646842 -0.151168  1.286750  1.236971  0.594569   \n",
       "4  0.340740  0.021220 -1.101971  0.673534  1.268718 -0.091452 -0.657666   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0 -0.784983  0.283103  1.462493 -1.786861 -1.006018  0.986097  \n",
       "1  1.114266 -0.635317 -0.734267  0.559641  0.994018 -1.014099  \n",
       "2 -0.310171 -0.864922 -0.368140  0.559641  0.994018 -1.014099  \n",
       "3  0.876859  0.512708 -0.002014  0.559641 -1.006018 -1.014099  \n",
       "4 -1.022389 -0.864922  0.730240  0.559641  0.994018 -1.014099  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### In addition to 'data.csv' file, we have a 'test_data.csv' file, but latter one does not have target data so we do not have the chance of testing our model with it. We split our dataset into 'training' and 'testing' datasets. And, we are going to see our models' accuracy by applying them on test dataset.\n",
    "\n",
    "### Splitting dataset into train and test dataset in the ratio 4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 20)\n",
      "(600, 20)\n"
     ]
    }
   ],
   "source": [
    "# check whether the split works correctly \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 1400 rows present in training dataset and 600 rows are present in testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 : IMPLEMENTING ML ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To predict the mobile phone prices, we are going to apply below algorithms respectively on the training and testing dataset. After that, we are going to choose the best model for our data set and create target values for test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target variables of the data set are discrete, hence, we are going to apply multiclass logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naresh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141,   3],\n",
       "       [  5, 451]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_lr)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train result: 0.99\n",
      "Accuracy: 0.9866666666666667\n",
      "AUC-ROC: 0.9841008771929824\n"
     ]
    }
   ],
   "source": [
    "print(\"Train result:\", lr.score(X_train, y_train))\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\n",
    "\n",
    "print(\"AUC-ROC:\", metrics.roc_auc_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naresh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17a46231a58>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logistic_model_proba = LogisticRegression()\n",
    "\n",
    "logistic_model_proba.fit(X_train, y_train)\n",
    "\n",
    "prediction_proba = lr.predict_proba(X_test)\n",
    "\n",
    "#the ROC-curve and PR-curve to represent our model\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_lr)\n",
    "acc = lr.score(X_test, y_pred_lr)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_lr)\n",
    "plt.plot(fpr, tpr, label=\"acc:%.2f auc:%.2f\" % (acc, auc), linewidth=3)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test, prediction_proba[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.plot(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8616666666666667\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#-------------finding the appropriate value of k---------------\n",
    "#METHOD 1------------\n",
    "score=[]\n",
    "for i in range(1,21):\n",
    "    knn=KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    score.append(knn.score(X_test,y_test))\n",
    "print(max(score))\n",
    "print(score.index(max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=8) #at k=8,the value is high i.e 0.4325\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 86  58]\n",
      " [ 30 426]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8533333333333334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_knn = metrics.accuracy_score(y_test, y_pred_knn)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobile Price Prediction\n",
    "\n",
    "IMPORT LIBRARY...\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "dataset=pd.read_csv('datasets_train.csv')\n",
    "\n",
    "dataset.head(5)\n",
    "\n",
    "# STEP 3 : DATA PREPROCESSING\n",
    "\n",
    "dataset.info()\n",
    "\n",
    "Note:\n",
    "1. No missing values\n",
    "2. Categorical data already handled\n",
    "3. No textual values\n",
    "\n",
    "SEPERATING DATASET INTO FEATURE MATRIX AND VECTOR OF PREDICTION:\n",
    "\n",
    "As mentioned above, our data have labels and we will apply supervised learning algorithms.\n",
    "We define our target column as \"y\" and rest of the data which are used as inputs as \"X\".\n",
    "\n",
    "X=dataset.iloc[:,0:20]\n",
    "X.head()\n",
    "\n",
    "y=dataset.iloc[:,20]\n",
    "y.unique()\n",
    "# We have four price ranges as target values and will do multi-class classification in our study.\n",
    "\n",
    "FEATURE SCALING : \n",
    "We need to normallize and scale the data, so we'll use MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()\n",
    "\n",
    "X=min_max.fit_transform(X) \n",
    "\n",
    "X=pd.DataFrame(X)\n",
    "\n",
    "X.head()\n",
    "\n",
    "In addition to 'data.csv' file, we have a 'test_data.csv' file, but latter one does not have target data so we do not have the chance of testing our model with it.\n",
    "We split our dataset into 'training' and 'testing' datasets. And, we are going to see our models' accuracy by applying them on  test dataset.\n",
    "\n",
    "Splitting dataset into train and test dataset in the ratio 4:1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# check whether the split works correctly \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "Now, our data is ready to be used as a sample for predicting models.\n",
    "\n",
    "# STEP 4 : IMPLEMENTING ML ALGORITHMS\n",
    "\n",
    "To predict the mobile phone prices, we are going to apply below algorithms respectively on the training and testing dataset.\n",
    "After that, we are going to choose the best model for our data set and create target values for test dataset.\n",
    "\n",
    "# Logistic Regression\n",
    "Target variables of the data set are discrete, hence, we are going to apply multiclass logistic regression model.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(multi_class = 'multinomial', solver = 'sag',  max_iter = 10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_lr)\n",
    "confusion_matrix\n",
    "\n",
    "print(\"Train result:\", lr.score(X_train, y_train))\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\n",
    "\n",
    "print(\"AUC-ROC:\", metrics.roc_auc_score(y_test, y_pred_lr,multi_class=\"ovo\"))\n",
    "\n",
    "ax=y_pred_lr.shape\n",
    "ax\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(y_pred_lr,ax[0],c=\"r\",label=\"prediction\")\n",
    "plt.show()\n",
    "\n",
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#-------------finding the appropriate value of k---------------\n",
    "#METHOD 1------------\n",
    "score=[]\n",
    "for i in range(1,21):\n",
    "    knn=KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    score.append(knn.score(X_test,y_test))\n",
    "print(max(score))\n",
    "print(score.index(max(score)))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=8) #at k=8,the value is high i.e 0.4325\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "acc_knn = metrics.accuracy_score(y_test, y_pred_knn)\n",
    "acc_knn\n",
    "\n",
    "sns.countplot(y_pred)\n",
    "\n",
    "sns.countplot(y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm\n",
    "#knn.score(X_test,y_test)\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2', 'Class 3','Class 4']))\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm,annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
